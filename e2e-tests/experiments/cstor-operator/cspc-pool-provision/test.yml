---
- hosts: localhost
  connection: local
  gather_facts: False

  vars_files:
    - test_vars.yml

  tasks:
    - block:

         ## Generating the testname for deployment
        - include_tasks: /e2e-tests/utils/fcm/create_testname.yml

         ## RECORD START-OF-TEST IN E2E RESULT CR
        - include_tasks: "/e2e-tests/utils/fcm/update_e2e_result_resource.yml"
          vars:
            status: 'SOT'

        - name: Getting the compute node name
          shell: kubectl get nodes --no-headers | grep -v master | awk {'print $1'} | head -{{ pool_count }} 
          register: nodes
          failed_when: "(nodes.stdout_lines|length) != pool_count|int"

        - name: Checking OpenEBS-CSPC-Operator is running
          shell: kubectl get pods -n {{ operator_ns }} -o jsonpath='{.items[?(@.metadata.labels.name=="cspc-operator")].status.phase}'
          register: cspc_status
          failed_when: "'Running' not in cspc_status.stdout"

        - block:
            - name: set the value for the disk count to fetch the unclaimed blockDevice from each node
              set_fact:
                disk_count: "{{ item.value.count }}"
              loop: "{{ lookup('dict', bd_count) }}"
              when: "'{{ pool_type }}' in item.key"

            # Creating the blockdevice template from blockdevice.j2 jinja template for each node
            - name: Add node labels for each nodes and create blockdevice template
              template:
                src: ./blockdevice.j2
                dest: ./blockdevice-{{ item[0] }}.yml
              with_together:
                - "{{ nodes.stdout_lines }}"

            - name: Getting the Unclaimed block-device count
              shell: kubectl get blockdevice -n {{ operator_ns }} -l kubernetes.io/hostname={{ item }} -o jsonpath='{.items[?(@.status.claimState=="Unclaimed")].metadata.name}' | tr " " "\n" | grep -v sparse | head -n "{{ disk_count }}"
              register: bd_count
              with_items: "{{ nodes.stdout_lines }}"

            - set_fact:
                device_count: "{{ bd_count|length}}"

            - name: Add the block devices for each node's block device template
              include_tasks: add_blockdevice.yml
              with_items: "{{ nodes.stdout_lines }}"
              loop_control:
                loop_var: outer_item

            # Insert the blockdevice template created for each nodes into cspc spec
            # blockinfile module will insert the external_files/block.
            # marker line template will be replaced with the values in marker_begin (default="BEGIN") and marker_end (default="END").
            - name: Include the blockdevice template in the CSPC spec
              blockinfile:
                dest: ./cspc.yml
                marker_end: "## {{ item }} Ansible Config ##"
                insertafter: pools
                state: present
                block: |
                  {{ lookup('file', './blockdevice-{{ item }}.yml') }}
              with_items:
                - "{{ nodes.stdout_lines }}"

            - name: Replacing the pool name in CSPC spec
              replace:
                path: ./cspc.yml
                regexp: "pool-name"
                replace: "{{ pool_name }}"

            - name: Replacing the namespace in CSPC spec
              replace:
                path: ./cspc.yml
                regexp: "operator_ns"
                replace: "{{ operator_ns }}"

            - name: Replacing the pool type in CSPC spec
              replace:
                path: ./cspc.yml
                regexp: "pool-type"
                replace: "{{ pool_type }}"

            - name: Replacing the storage class name in CSPC spec
              replace:
                path: ./cspc.yml
                regexp: "sc-name"
                replace: "{{ sc_name }}"

            - name: Display cspc.yml for verification
              debug: var=item
              with_file:
              - "cspc.yml"

            - name: Create cstor disk pool
              shell: kubectl apply -f cspc.yml
              args:
                executable: /bin/bash

            - name: Check whether cspc is created
              shell: >
                kubectl get cspc -n {{ operator_ns }} -o custom-columns=:.metadata.name --no-headers
              args:
                executable: /bin/bash
              register: cspc_name
              until: "pool_name in cspc_name.stdout"
              delay: 30
              retries: 10

            - name: Verify the status of CSPI
              shell: >
                kubectl get cspi -n {{ operator_ns}} -l openebs.io/cstor-pool-cluster={{ pool_name }}
                -o custom-columns=:.status.phase --no-headers
              args:
                executable: /bin/bash
              register: cspi_status
              until: "((cspi_status.stdout_lines|unique)|length) == 1 and 'ONLINE' in cspi_status.stdout"
              delay: 5
              retries: 60

            - name: Obtain the CSPI name to verify the status
              shell: >
                kubectl get cspi -n {{ operator_ns}} -l openebs.io/cstor-pool-cluster={{ pool_name }}
                -o custom-columns=:.metadata.name --no-headers
              args:
                executable: /bin/bash
              register: cspi_name

            - name: Verify if the cStor Pool pods are Running
              shell: >
                kubectl get pods -n {{ operator_ns }} -l openebs.io/cstor-pool-instance={{ item }}
                --no-headers -o custom-columns=:status.phase
              args:
                executable: /bin/bash
              register: poolcount
              with_items: "{{ cspi_name.stdout_lines }}"
              until: "((poolcount.stdout_lines|unique)|length) == 1 and 'Running' in poolcount.stdout"
              retries: 30
              delay: 10

            - name: Get cStor Pool pod names to verify the container statuses and check the required number of pools created. 
              shell: >
                kubectl get pods -n {{ operator_ns }} -l openebs.io/cstor-pool-cluster={{ pool_name }}
                --no-headers -o=custom-columns=NAME:".metadata.name"
              args:
                executable: /bin/bash
              register: cstor_pool_pod
              failed_when: "(cstor_pool_pod.stdout_lines|length) != pool_count|int"

            - name: Get the runningStatus of pool pod
              shell: >
                kubectl get pod {{ item }} -n {{ operator_ns }}
                -o=jsonpath='{range .status.containerStatuses[*]}{.state}{"\n"}{end}' |
                grep -w running | wc -l
              args:
                executable: /bin/bash
              register: runningStatusCount
              with_items: "{{ cstor_pool_pod.stdout_lines }}"
              until: "runningStatusCount.stdout == device_count"
              delay: 30
              retries: 10

            - name: Check if the storage class is created
              shell: kubectl get sc
              args:
                executable: /bin/bash
              register: sc_list
              failed_when: "sc_name not in sc_list.stdout"

          when: deploy_mode == "create"

        - block:

            - name: Obtain the CSPI list to verify the existence of replicas
              shell: 
                 kubectl get cspi -n {{ operator_ns }} -l openebs.io/cstor-pool-cluster={{ pool_name }} 
                 -o custom-columns=:.metadata.name --no-headers
              args:
                executable: /bin/bash
              register: cspi_list
               
            - name: Verify if the replicas are removed
              shell: >
                 kubectl get cspi -n {{ operator_ns }} {{ item }}
                 -o custom-columns=:.status.provisionedReplicas --no-headers
              args:
                executable: /bin/bash
              register: cspi_rep_status
              with_items: "{{ cspi_list.stdout_lines }}"
              until: "'0' in cspi_rep_status.stdout "
              retries: 30
              delay: 10
                            
            - name: Remove the CStor Pool Cluster
              shell: >
                kubectl delete cspc {{ pool_name }} -n {{ operator_ns }}
              args:
                executable: /bin/bash

            - name: Verify if the CStor Pool Cluster is deleted
              shell: >
                kubectl get cspc -n {{ operator_ns }}
              register: cspc_status
              until: '"{{ pool_name }}" not in cspc_status.stdout'
              retries: 30
              delay: 10

            - name: Verify if the CSPI is getting removed
              shell: >
                kubectl get cspi -n {{ operator_ns }} -l openebs.io/cstor-pool-cluster={{ pool_name }}
              args:
                executable: /bin/bash
              register: cspi_status
              until: "'No resources found.' in cspi_status.stderr"
              retries: 30
              delay: 10

            - name: Verify if the cStor pool pods are deleted
              shell:
                kubectl get pods -n {{ operator_ns }} -l openebs.io/cstor-pool-cluster={{ pool_name }}
              args:
                executable: /bin/bash
              register: pool_status
              until: "'No resources found.' in pool_status.stderr"
              retries: 30
              delay: 10

          when: deploy_mode == "delete"

        - set_fact:
            flag: "Pass"

      rescue:
        - set_fact:
            flag: "Fail"

      always:
            ## RECORD END-OF-TEST IN E2E RESULT CR
          - include_tasks: /e2e-tests/utils/fcm/update_e2e_result_resource.yml
            vars:
              status: 'EOT'
